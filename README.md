# Training Parallelism



## Data Parallelism

## Model Parallelism

## Pipeline Parallelism

## Tensor Parallelism


#### References

[1] Weng, Lilian. (Sep 2021). How to train really large models on many GPUs? Lilâ€™Log. https://lilianweng.github.io/posts/2021-09-25-train-large/.
