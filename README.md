# Techniques for Training Large Language Models on Multiple GPUs

<img width="689" alt="Screenshot 2022-08-31 at 1 50 32 PM" src="https://github.com/aniket-mish/parallelism/assets/71699313/a5925986-5c7f-4875-ba5a-9678ed24d480">

<img width="940" alt="Screenshot 2022-08-31 at 1 51 35 PM" src="https://github.com/aniket-mish/parallelism/assets/71699313/02fe75a7-4a0a-4108-addc-d62aaf9bb226">

<img width="907" alt="Screenshot 2022-09-02 at 3 47 01 PM" src="https://github.com/aniket-mish/parallelism/assets/71699313/4828aa82-6fc6-4852-8a0f-5b51bb0b6fae">

PyTorch Distributed Data Parallel



#### References

[1] [How to train really large models on many GPUs? Lilâ€™Log](https://lilianweng.github.io/posts/2021-09-25-train-large/)

[2] https://openai.com/blog/techniques-for-training-large-neural-networks/

[3] https://huggingface.co/docs/transformers/perf_train_gpu_many

[4] https://pytorch.org/tutorials/intermediate/ddp_tutorial.html
